{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":20270,"databundleVersionId":1222630,"sourceType":"competition"},{"sourceId":1243687,"sourceType":"datasetVersion","datasetId":690737}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Melanoma starter pipeline by [@shonenkov](https://www.kaggle.com/shonenkov)","metadata":{}},{"cell_type":"markdown","source":"# Main ideas\n\n\n- Using External Data\n- StratifyGroupKFold\n- Focal Loss / Label Smoothing\n- BalanceClassSampler\n- SimpleAugs\n- 512x512 image size\n- EfficientNet","metadata":{}},{"cell_type":"markdown","source":"# Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install -q efficientnet_pytorch > /dev/null","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-09-30T06:42:55.236512Z","iopub.execute_input":"2024-09-30T06:42:55.237401Z","iopub.status.idle":"2024-09-30T06:43:06.983753Z","shell.execute_reply.started":"2024-09-30T06:42:55.237346Z","shell.execute_reply":"2024-09-30T06:43:06.982631Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"!pip install catalyst","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:06.986543Z","iopub.execute_input":"2024-09-30T06:43:06.987429Z","iopub.status.idle":"2024-09-30T06:43:18.693392Z","shell.execute_reply.started":"2024-09-30T06:43:06.987380Z","shell.execute_reply":"2024-09-30T06:43:18.692063Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Requirement already satisfied: catalyst in /opt/conda/lib/python3.10/site-packages (22.4)\nRequirement already satisfied: numpy>=1.18 in /opt/conda/lib/python3.10/site-packages (from catalyst) (1.26.4)\nRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from catalyst) (2.4.0)\nRequirement already satisfied: accelerate>=0.5.1 in /opt/conda/lib/python3.10/site-packages (from catalyst) (0.34.2)\nRequirement already satisfied: hydra-slayer>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from catalyst) (0.5.0)\nRequirement already satisfied: tqdm>=4.33.0 in /opt/conda/lib/python3.10/site-packages (from catalyst) (4.66.4)\nRequirement already satisfied: tensorboardX>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from catalyst) (2.6.2.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.5.1->catalyst) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.5.1->catalyst) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.5.1->catalyst) (6.0.2)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.5.1->catalyst) (0.25.0)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.5.1->catalyst) (0.4.5)\nRequirement already satisfied: protobuf>=3.20 in /opt/conda/lib/python3.10/site-packages (from tensorboardX>=2.1.0->catalyst) (3.20.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->catalyst) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->catalyst) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->catalyst) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->catalyst) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->catalyst) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->catalyst) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.5.1->catalyst) (2.32.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate>=0.5.1->catalyst) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->catalyst) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->catalyst) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.5.1->catalyst) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.5.1->catalyst) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.5.1->catalyst) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.5.1->catalyst) (2024.8.30)\n","output_type":"stream"}]},{"cell_type":"code","source":"from glob import glob\nimport pandas as pd\nfrom sklearn.model_selection import GroupKFold\nimport cv2\nfrom skimage import io\nimport albumentations as A\nimport torch\nimport os\nfrom datetime import datetime\nimport time\nimport random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport albumentations as A\nimport matplotlib.pyplot as plt\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom torch.nn import functional as F\nfrom glob import glob\nimport sklearn\nfrom torch import nn\nimport warnings\n\nwarnings.filterwarnings(\"ignore\") \nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n\nSEED = 42\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-09-30T06:43:18.695027Z","iopub.execute_input":"2024-09-30T06:43:18.695416Z","iopub.status.idle":"2024-09-30T06:43:18.707491Z","shell.execute_reply.started":"2024-09-30T06:43:18.695381Z","shell.execute_reply":"2024-09-30T06:43:18.706713Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"# External data\n\nI have prepared kernel with merging data. Don't forget to read [this kernel](https://www.kaggle.com/shonenkov/merge-external-data) ;)","metadata":{}},{"cell_type":"code","source":"DATA_PATH = '../input/melanoma-merged-external-data-512x512-jpeg'","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:18.710231Z","iopub.execute_input":"2024-09-30T06:43:18.711019Z","iopub.status.idle":"2024-09-30T06:43:18.721030Z","shell.execute_reply.started":"2024-09-30T06:43:18.710985Z","shell.execute_reply":"2024-09-30T06:43:18.720182Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"# StratifyGroupKFold\n\nI think group by patient_id is very important. Also I think that stratify by sex, target, source, anatom_site_general_challenge also useful.\nCode with getting folds you can find [here](https://www.kaggle.com/shonenkov/merge-external-data)","metadata":{}},{"cell_type":"code","source":"df_folds = pd.read_csv(f'{DATA_PATH}/folds.csv', index_col='image_id')","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:18.722175Z","iopub.execute_input":"2024-09-30T06:43:18.722446Z","iopub.status.idle":"2024-09-30T06:43:18.852830Z","shell.execute_reply.started":"2024-09-30T06:43:18.722417Z","shell.execute_reply":"2024-09-30T06:43:18.851828Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"set(df_folds[df_folds['fold'] == 0]['patient_id'].values).intersection(df_folds[df_folds['fold'] == 1]['patient_id'].values)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:18.854239Z","iopub.execute_input":"2024-09-30T06:43:18.855014Z","iopub.status.idle":"2024-09-30T06:43:18.875167Z","shell.execute_reply.started":"2024-09-30T06:43:18.854967Z","shell.execute_reply":"2024-09-30T06:43:18.874263Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"set()"},"metadata":{}}]},{"cell_type":"code","source":"df_folds[df_folds['fold'] == 0]['target'].hist();","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:18.876282Z","iopub.execute_input":"2024-09-30T06:43:18.876572Z","iopub.status.idle":"2024-09-30T06:43:19.381768Z","shell.execute_reply.started":"2024-09-30T06:43:18.876541Z","shell.execute_reply":"2024-09-30T06:43:19.380852Z"},"trusted":true},"execution_count":56,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"df_folds[df_folds['fold'] == 1]['target'].hist();","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:19.383016Z","iopub.execute_input":"2024-09-30T06:43:19.383339Z","iopub.status.idle":"2024-09-30T06:43:19.636918Z","shell.execute_reply.started":"2024-09-30T06:43:19.383306Z","shell.execute_reply":"2024-09-30T06:43:19.635971Z"},"trusted":true},"execution_count":57,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAjkAAAGdCAYAAADwjmIIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApaklEQVR4nO3de3TU9Z3/8VcSMpOEkoTAya1GjLqViyAaaogI9RISBV1oWStLitk2QsWk25BzoCIYIKBoBOSWyqIiehYKuissBTZmGhYRCBcjWREQdaHFXXfCWi7DRZIh+f7+6Mn35xhuSWcmzofn4xzOcT7f9/cz7+87ibzOd2ZImGVZlgAAAAwT3tENAAAABAIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgpE4d3UBHam5u1pdffqkuXbooLCyso9sBAABXwbIsnT59WqmpqQoPv/T9mms65Hz55ZdKS0vr6DYAAEA7fPHFF7ruuusuefyaDjldunSR9JchxcbG+m1fr9erqqoq5eTkKDIy0m/7whdzDh5mHRzMOTiYc3AEcs4ej0dpaWn23+OXck2HnJaXqGJjY/0ecmJiYhQbG8sPUAAx5+Bh1sHBnIODOQdHMOZ8pbea8MZjAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACN16ugGTHbrjHfV0HT5XwP/XfLH54d3dAsAAPgNd3IAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGCkNoecrVu36uGHH1ZqaqrCwsK0bt06n+OWZam0tFQpKSmKjo5Wdna2PvvsM5+a48ePKy8vT7GxsYqPj1dBQYHOnDnjU/PRRx9p8ODBioqKUlpamsrLy1v18vbbb6tnz56KiopS3759tWnTprZeDgAAMFSbQ87Zs2d12223qaKi4qLHy8vLtWjRIi1dulS7du1S586dlZubq/Pnz9s1eXl52r9/v1wulzZs2KCtW7dq/Pjx9nGPx6OcnBz16NFDtbW1evHFFzVjxgwtW7bMrtmxY4f+/u//XgUFBdq7d69GjhypkSNH6uOPP27rJQEAAAN1ausJDz74oB588MGLHrMsSwsWLNC0adM0YsQISdKbb76ppKQkrVu3TqNHj9bBgwdVWVmpPXv2aMCAAZKkxYsXa9iwYZo7d65SU1O1cuVKNTY2avny5XI4HOrTp4/q6uo0f/58OwwtXLhQDzzwgCZNmiRJmjVrllwul5YsWaKlS5e2axgAAMAcfn1PzpEjR+R2u5WdnW2vxcXFKTMzUzU1NZKkmpoaxcfH2wFHkrKzsxUeHq5du3bZNUOGDJHD4bBrcnNzdejQIZ04ccKu+ebztNS0PA8AALi2tflOzuW43W5JUlJSks96UlKSfcztdisxMdG3iU6dlJCQ4FOTnp7eao+WY127dpXb7b7s81xMQ0ODGhoa7Mcej0eS5PV65fV6r/o6r6RlL2e45bc9g8GfMwiGln5Dre9QxKyDgzkHB3MOjkDO+Wr39GvI+a6bM2eOZs6c2Wq9qqpKMTExfn++WQOa/b5nIIXqG7ddLldHt3DNYNbBwZyDgzkHRyDmfO7cuauq82vISU5OliTV19crJSXFXq+vr1f//v3tmmPHjvmcd+HCBR0/ftw+Pzk5WfX19T41LY+vVNNy/GKmTJmikpIS+7HH41FaWppycnIUGxvblku9LK/XK5fLpWc+CFdDc5jf9g20j2fkdnQLbdIy56FDhyoyMrKj2zEasw4O5hwczDk4AjnnlldirsSvISc9PV3Jycmqrq62Q43H49GuXbs0YcIESVJWVpZOnjyp2tpaZWRkSJI2b96s5uZmZWZm2jVTp06V1+u1B+NyuXTLLbeoa9eudk11dbWKi4vt53e5XMrKyrpkf06nU06ns9V6ZGRkQL7RG5rD1NAUOiEnVH/YA/X1Q2vMOjiYc3Aw5+AIxJyvdr82v/H4zJkzqqurU11dnaS/vNm4rq5OR48eVVhYmIqLizV79mytX79e+/bt02OPPabU1FSNHDlSktSrVy898MADGjdunHbv3q3t27erqKhIo0ePVmpqqiRpzJgxcjgcKigo0P79+7VmzRotXLjQ5y7Mr3/9a1VWVmrevHn65JNPNGPGDH3wwQcqKipq6yUBAAADtflOzgcffKB7773XftwSPPLz87VixQpNnjxZZ8+e1fjx43Xy5EndfffdqqysVFRUlH3OypUrVVRUpPvvv1/h4eEaNWqUFi1aZB+Pi4tTVVWVCgsLlZGRoe7du6u0tNTn39K56667tGrVKk2bNk1PP/20/uZv/kbr1q3Trbfe2q5BAAAAs7Q55Nxzzz2yrEt/aigsLExlZWUqKyu7ZE1CQoJWrVp12efp16+f3n///cvWPPLII3rkkUcu3zAAALgm8burAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYye8hp6mpSc8884zS09MVHR2tm266SbNmzZJlWXaNZVkqLS1VSkqKoqOjlZ2drc8++8xnn+PHjysvL0+xsbGKj49XQUGBzpw541Pz0UcfafDgwYqKilJaWprKy8v9fTkAACBE+T3kvPDCC3r55Ze1ZMkSHTx4UC+88ILKy8u1ePFiu6a8vFyLFi3S0qVLtWvXLnXu3Fm5ubk6f/68XZOXl6f9+/fL5XJpw4YN2rp1q8aPH28f93g8ysnJUY8ePVRbW6sXX3xRM2bM0LJly/x9SQAAIAR18veGO3bs0IgRIzR8+HBJ0g033KDf/e532r17t6S/3MVZsGCBpk2bphEjRkiS3nzzTSUlJWndunUaPXq0Dh48qMrKSu3Zs0cDBgyQJC1evFjDhg3T3LlzlZqaqpUrV6qxsVHLly+Xw+FQnz59VFdXp/nz5/uEIQAAcG3y+52cu+66S9XV1fr0008lSf/5n/+pbdu26cEHH5QkHTlyRG63W9nZ2fY5cXFxyszMVE1NjSSppqZG8fHxdsCRpOzsbIWHh2vXrl12zZAhQ+RwOOya3NxcHTp0SCdOnPD3ZQEAgBDj9zs5Tz31lDwej3r27KmIiAg1NTXp2WefVV5eniTJ7XZLkpKSknzOS0pKso+53W4lJib6NtqpkxISEnxq0tPTW+3Rcqxr166temtoaFBDQ4P92OPxSJK8Xq+8Xm+7r/nbWvZyhltXqPxu8ecMgqGl31DrOxQx6+BgzsHBnIMjkHO+2j39HnLeeustrVy5UqtWrbJfQiouLlZqaqry8/P9/XRtMmfOHM2cObPVelVVlWJiYvz+fLMGNPt9z0DatGlTR7fQLi6Xq6NbuGYw6+BgzsHBnIMjEHM+d+7cVdX5PeRMmjRJTz31lEaPHi1J6tu3r/70pz9pzpw5ys/PV3JysiSpvr5eKSkp9nn19fXq37+/JCk5OVnHjh3z2ffChQs6fvy4fX5ycrLq6+t9aloet9R825QpU1RSUmI/9ng8SktLU05OjmJjY/+Kq/bl9Xrlcrn0zAfhamgO89u+gfbxjNyObqFNWuY8dOhQRUZGdnQ7RmPWwcGcg4M5B0cg59zySsyV+D3knDt3TuHhvm/1iYiIUHPzX+5qpKenKzk5WdXV1Xao8Xg82rVrlyZMmCBJysrK0smTJ1VbW6uMjAxJ0ubNm9Xc3KzMzEy7ZurUqfJ6vfbwXC6Xbrnllou+VCVJTqdTTqez1XpkZGRAvtEbmsPU0BQ6ISdUf9gD9fVDa8w6OJhzcDDn4AjEnK92P7+/8fjhhx/Ws88+q40bN+qPf/yj1q5dq/nz5+vHP/6xJCksLEzFxcWaPXu21q9fr3379umxxx5TamqqRo4cKUnq1auXHnjgAY0bN067d+/W9u3bVVRUpNGjRys1NVWSNGbMGDkcDhUUFGj//v1as2aNFi5c6HOnBgAAXLv8fidn8eLFeuaZZ/Tkk0/q2LFjSk1N1S9/+UuVlpbaNZMnT9bZs2c1fvx4nTx5UnfffbcqKysVFRVl16xcuVJFRUW6//77FR4erlGjRmnRokX28bi4OFVVVamwsFAZGRnq3r27SktL+fg4AACQFICQ06VLFy1YsEALFiy4ZE1YWJjKyspUVlZ2yZqEhAStWrXqss/Vr18/vf/+++1tFQAAGIzfXQUAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEgBCTn/8z//o5/97Gfq1q2boqOj1bdvX33wwQf2ccuyVFpaqpSUFEVHRys7O1ufffaZzx7Hjx9XXl6eYmNjFR8fr4KCAp05c8an5qOPPtLgwYMVFRWltLQ0lZeXB+JyAABACPJ7yDlx4oQGDRqkyMhI/fu//7sOHDigefPmqWvXrnZNeXm5Fi1apKVLl2rXrl3q3LmzcnNzdf78ebsmLy9P+/fvl8vl0oYNG7R161aNHz/ePu7xeJSTk6MePXqotrZWL774ombMmKFly5b5+5IAAEAI6uTvDV944QWlpaXp9ddft9fS09Pt/7YsSwsWLNC0adM0YsQISdKbb76ppKQkrVu3TqNHj9bBgwdVWVmpPXv2aMCAAZKkxYsXa9iwYZo7d65SU1O1cuVKNTY2avny5XI4HOrTp4/q6uo0f/58nzAEAACuTX4POevXr1dubq4eeeQRvffee/r+97+vJ598UuPGjZMkHTlyRG63W9nZ2fY5cXFxyszMVE1NjUaPHq2amhrFx8fbAUeSsrOzFR4erl27dunHP/6xampqNGTIEDkcDrsmNzdXL7zwgk6cOOFz56hFQ0ODGhoa7Mcej0eS5PV65fV6/TaDlr2c4Zbf9gwGf84gGFr6DbW+QxGzDg7mHBzMOTgCOeer3dPvIefw4cN6+eWXVVJSoqefflp79uzRP/7jP8rhcCg/P19ut1uSlJSU5HNeUlKSfcztdisxMdG30U6dlJCQ4FPzzTtE39zT7XZfNOTMmTNHM2fObLVeVVWlmJiYdl7xpc0a0Oz3PQNp06ZNHd1Cu7hcro5u4ZrBrIODOQcHcw6OQMz53LlzV1Xn95DT3NysAQMG6LnnnpMk3X777fr444+1dOlS5efn+/vp2mTKlCkqKSmxH3s8HqWlpSknJ0exsbF+ex6v1yuXy6VnPghXQ3OY3/YNtI9n5HZ0C23SMuehQ4cqMjKyo9sxGrMODuYcHMw5OAI555ZXYq7E7yEnJSVFvXv39lnr1auX/vVf/1WSlJycLEmqr69XSkqKXVNfX6/+/fvbNceOHfPZ48KFCzp+/Lh9fnJysurr631qWh631Hyb0+mU0+lstR4ZGRmQb/SG5jA1NIVOyAnVH/ZAff3QGrMODuYcHMw5OAIx56vdz++frho0aJAOHTrks/bpp5+qR48ekv7yJuTk5GRVV1fbxz0ej3bt2qWsrCxJUlZWlk6ePKna2lq7ZvPmzWpublZmZqZds3XrVp/X5Vwul2655ZaLvlQFAACuLX4PORMnTtTOnTv13HPP6fPPP9eqVau0bNkyFRYWSpLCwsJUXFys2bNna/369dq3b58ee+wxpaamauTIkZL+cufngQce0Lhx47R7925t375dRUVFGj16tFJTUyVJY8aMkcPhUEFBgfbv3681a9Zo4cKFPi9HAQCAa5ffX6764Q9/qLVr12rKlCkqKytTenq6FixYoLy8PLtm8uTJOnv2rMaPH6+TJ0/q7rvvVmVlpaKiouyalStXqqioSPfff7/Cw8M1atQoLVq0yD4eFxenqqoqFRYWKiMjQ927d1dpaSkfHwcAAJICEHIk6aGHHtJDDz10yeNhYWEqKytTWVnZJWsSEhK0atWqyz5Pv3799P7777e7TwAAYC5+dxUAADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMFPOQ8//zzCgsLU3Fxsb12/vx5FRYWqlu3bvre976nUaNGqb6+3ue8o0ePavjw4YqJiVFiYqImTZqkCxcu+NRs2bJFd9xxh5xOp26++WatWLEi0JcDAABCREBDzp49e/RP//RP6tevn8/6xIkT9fvf/15vv/223nvvPX355Zf6yU9+Yh9vamrS8OHD1djYqB07duiNN97QihUrVFpaatccOXJEw4cP17333qu6ujoVFxfr8ccf17vvvhvISwIAACEiYCHnzJkzysvL0yuvvKKuXbva66dOndJrr72m+fPn67777lNGRoZef/117dixQzt37pQkVVVV6cCBA/rnf/5n9e/fXw8++KBmzZqliooKNTY2SpKWLl2q9PR0zZs3T7169VJRUZH+7u/+Ti+99FKgLgkAAISQToHauLCwUMOHD1d2drZmz55tr9fW1srr9So7O9te69mzp66//nrV1NRo4MCBqqmpUd++fZWUlGTX5ObmasKECdq/f79uv/121dTU+OzRUvPNl8W+raGhQQ0NDfZjj8cjSfJ6vfJ6vX/tJdta9nKGW37bMxj8OYNgaOk31PoORcw6OJhzcDDn4AjknK92z4CEnNWrV+vDDz/Unj17Wh1zu91yOByKj4/3WU9KSpLb7bZrvhlwWo63HLtcjcfj0ddff63o6OhWzz1nzhzNnDmz1XpVVZViYmKu/gKv0qwBzX7fM5A2bdrU0S20i8vl6ugWrhnMOjiYc3Aw5+AIxJzPnTt3VXV+DzlffPGFfv3rX8vlcikqKsrf2/9VpkyZopKSEvuxx+NRWlqacnJyFBsb67fn8Xq9crlceuaDcDU0h/lt30D7eEZuR7fQJi1zHjp0qCIjIzu6HaMx6+BgzsHBnIMjkHNueSXmSvwecmpra3Xs2DHdcccd9lpTU5O2bt2qJUuW6N1331VjY6NOnjzpczenvr5eycnJkqTk5GTt3r3bZ9+WT199s+bbn8iqr69XbGzsRe/iSJLT6ZTT6Wy1HhkZGZBv9IbmMDU0hU7ICdUf9kB9/dAasw4O5hwczDk4AjHnq93P7288vv/++7Vv3z7V1dXZfwYMGKC8vDz7vyMjI1VdXW2fc+jQIR09elRZWVmSpKysLO3bt0/Hjh2za1wul2JjY9W7d2+75pt7tNS07AEAAK5tfr+T06VLF916660+a507d1a3bt3s9YKCApWUlCghIUGxsbH61a9+paysLA0cOFCSlJOTo969e2vs2LEqLy+X2+3WtGnTVFhYaN+JeeKJJ7RkyRJNnjxZv/jFL7R582a99dZb2rhxo78vCQAAhKCAfbrqcl566SWFh4dr1KhRamhoUG5urn7729/axyMiIrRhwwZNmDBBWVlZ6ty5s/Lz81VWVmbXpKena+PGjZo4caIWLlyo6667Tq+++qpyc0PrfSUAACAwghJytmzZ4vM4KipKFRUVqqiouOQ5PXr0uOKnfe655x7t3bvXHy0CAADD8LurAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYye8hZ86cOfrhD3+oLl26KDExUSNHjtShQ4d8as6fP6/CwkJ169ZN3/ve9zRq1CjV19f71Bw9elTDhw9XTEyMEhMTNWnSJF24cMGnZsuWLbrjjjvkdDp18803a8WKFf6+HAAAEKL8HnLee+89FRYWaufOnXK5XPJ6vcrJydHZs2ftmokTJ+r3v/+93n77bb333nv68ssv9ZOf/MQ+3tTUpOHDh6uxsVE7duzQG2+8oRUrVqi0tNSuOXLkiIYPH657771XdXV1Ki4u1uOPP653333X35cEAABCUCd/b1hZWenzeMWKFUpMTFRtba2GDBmiU6dO6bXXXtOqVat03333SZJef/119erVSzt37tTAgQNVVVWlAwcO6A9/+IOSkpLUv39/zZo1S7/5zW80Y8YMORwOLV26VOnp6Zo3b54kqVevXtq2bZteeukl5ebm+vuyAABAiPF7yPm2U6dOSZISEhIkSbW1tfJ6vcrOzrZrevbsqeuvv141NTUaOHCgampq1LdvXyUlJdk1ubm5mjBhgvbv36/bb79dNTU1Pnu01BQXF1+yl4aGBjU0NNiPPR6PJMnr9crr9f7V19qiZS9nuOW3PYPBnzMIhpZ+Q63vUMSsg4M5BwdzDo5Azvlq9wxoyGlublZxcbEGDRqkW2+9VZLkdrvlcDgUHx/vU5uUlCS3223XfDPgtBxvOXa5Go/Ho6+//lrR0dGt+pkzZ45mzpzZar2qqkoxMTHtu8jLmDWg2e97BtKmTZs6uoV2cblcHd3CNYNZBwdzDg7mHByBmPO5c+euqi6gIaewsFAff/yxtm3bFsinuWpTpkxRSUmJ/djj8SgtLU05OTmKjY312/N4vV65XC4980G4GprD/LZvoH08I7Re5muZ89ChQxUZGdnR7RiNWQcHcw4O5hwcgZxzyysxVxKwkFNUVKQNGzZo69atuu666+z15ORkNTY26uTJkz53c+rr65WcnGzX7N6922e/lk9ffbPm25/Iqq+vV2xs7EXv4kiS0+mU0+lstR4ZGRmQb/SG5jA1NIVOyAnVH/ZAff3QGrMODuYcHMw5OAIx56vdz++frrIsS0VFRVq7dq02b96s9PR0n+MZGRmKjIxUdXW1vXbo0CEdPXpUWVlZkqSsrCzt27dPx44ds2tcLpdiY2PVu3dvu+abe7TUtOwBAACubX6/k1NYWKhVq1bp3/7t39SlSxf7PTRxcXGKjo5WXFycCgoKVFJSooSEBMXGxupXv/qVsrKyNHDgQElSTk6OevfurbFjx6q8vFxut1vTpk1TYWGhfSfmiSee0JIlSzR58mT94he/0ObNm/XWW29p48aN/r4kAAAQgvx+J+fll1/WqVOndM899yglJcX+s2bNGrvmpZde0kMPPaRRo0ZpyJAhSk5O1jvvvGMfj4iI0IYNGxQREaGsrCz97Gc/02OPPaaysjK7Jj09XRs3bpTL5dJtt92mefPm6dVXX+Xj4wAAQFIA7uRY1pU/Nh0VFaWKigpVVFRcsqZHjx5X/LTPPffco71797a5RwAAYD5+dxUAADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICROnV0AwAA4MpueGpjR7fQJs4IS+V3dmwP3MkBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADBSyIeciooK3XDDDYqKilJmZqZ2797d0S0BAIDvgJAOOWvWrFFJSYmmT5+uDz/8ULfddptyc3N17Nixjm4NAAB0sJAOOfPnz9e4ceP085//XL1799bSpUsVExOj5cuXd3RrAACgg3Xq6Abaq7GxUbW1tZoyZYq9Fh4eruzsbNXU1Fz0nIaGBjU0NNiPT506JUk6fvy4vF6v33rzer06d+6cOnnD1dQc5rd9A+3Pf/5zR7fQJi1z/vOf/6zIyMiObsdozDo4mHNwhOqcO10429EttEmnZkvnzjUHZM6nT5+WJFmWdfke/PqsQfTVV1+pqalJSUlJPutJSUn65JNPLnrOnDlzNHPmzFbr6enpAekx1HSf19EdAABMMibA+58+fVpxcXGXPB6yIac9pkyZopKSEvtxc3Ozjh8/rm7duikszH93XDwej9LS0vTFF18oNjbWb/vCF3MOHmYdHMw5OJhzcARyzpZl6fTp00pNTb1sXciGnO7duysiIkL19fU+6/X19UpOTr7oOU6nU06n02ctPj4+UC0qNjaWH6AgYM7Bw6yDgzkHB3MOjkDN+XJ3cFqE7BuPHQ6HMjIyVF1dba81NzerurpaWVlZHdgZAAD4LgjZOzmSVFJSovz8fA0YMEB33nmnFixYoLNnz+rnP/95R7cGAAA6WEiHnEcffVT/93//p9LSUrndbvXv31+VlZWt3owcbE6nU9OnT2/10hj8izkHD7MODuYcHMw5OL4Lcw6zrvT5KwAAgBAUsu/JAQAAuBxCDgAAMBIhBwAAGImQAwAAjETIaaeKigrdcMMNioqKUmZmpnbv3n3Z+rfffls9e/ZUVFSU+vbtq02bNgWp09DWljm/8sorGjx4sLp27aquXbsqOzv7il8X/EVbv59brF69WmFhYRo5cmRgGzRIW2d98uRJFRYWKiUlRU6nUz/4wQ/4/8dVaOucFyxYoFtuuUXR0dFKS0vTxIkTdf78+SB1G5q2bt2qhx9+WKmpqQoLC9O6deuueM6WLVt0xx13yOl06uabb9aKFSsC26SFNlu9erXlcDis5cuXW/v377fGjRtnxcfHW/X19Ret3759uxUREWGVl5dbBw4csKZNm2ZFRkZa+/btC3LnoaWtcx4zZoxVUVFh7d271zp48KD1D//wD1ZcXJz13//930HuPLS0dc4tjhw5Yn3/+9+3Bg8ebI0YMSI4zYa4ts66oaHBGjBggDVs2DBr27Zt1pEjR6wtW7ZYdXV1Qe48tLR1zitXrrScTqe1cuVK68iRI9a7775rpaSkWBMnTgxy56Fl06ZN1tSpU6133nnHkmStXbv2svWHDx+2YmJirJKSEuvAgQPW4sWLrYiICKuysjJgPRJy2uHOO++0CgsL7cdNTU1WamqqNWfOnIvW//SnP7WGDx/us5aZmWn98pe/DGifoa6tc/62CxcuWF26dLHeeOONQLVohPbM+cKFC9Zdd91lvfrqq1Z+fj4h5yq1ddYvv/yydeONN1qNjY3BatEIbZ1zYWGhdd999/mslZSUWIMGDQponya5mpAzefJkq0+fPj5rjz76qJWbmxuwvni5qo0aGxtVW1ur7Oxsey08PFzZ2dmqqam56Dk1NTU+9ZKUm5t7yXq0b87fdu7cOXm9XiUkJASqzZDX3jmXlZUpMTFRBQUFwWjTCO2Z9fr165WVlaXCwkIlJSXp1ltv1XPPPaempqZgtR1y2jPnu+66S7W1tfZLWocPH9amTZs0bNiwoPR8reiIvwtD+l887ghfffWVmpqaWv2ryklJSfrkk08ueo7b7b5ovdvtDlifoa49c/623/zmN0pNTW31Q4X/rz1z3rZtm1577TXV1dUFoUNztGfWhw8f1ubNm5WXl6dNmzbp888/15NPPimv16vp06cHo+2Q0545jxkzRl999ZXuvvtuWZalCxcu6IknntDTTz8djJavGZf6u9Dj8ejrr79WdHS035+TOzkw0vPPP6/Vq1dr7dq1ioqK6uh2jHH69GmNHTtWr7zyirp3797R7RivublZiYmJWrZsmTIyMvToo49q6tSpWrp0aUe3ZpQtW7boueee029/+1t9+OGHeuedd7Rx40bNmjWro1vDX4k7OW3UvXt3RUREqL6+3me9vr5eycnJFz0nOTm5TfVo35xbzJ07V88//7z+8Ic/qF+/foFsM+S1dc7/9V//pT/+8Y96+OGH7bXm5mZJUqdOnXTo0CHddNNNgW06RLXnezolJUWRkZGKiIiw13r16iW3263GxkY5HI6A9hyK2jPnZ555RmPHjtXjjz8uSerbt6/Onj2r8ePHa+rUqQoP536AP1zq78LY2NiA3MWRuJPTZg6HQxkZGaqurrbXmpubVV1draysrIuek5WV5VMvSS6X65L1aN+cJam8vFyzZs1SZWWlBgwYEIxWQ1pb59yzZ0/t27dPdXV19p+//du/1b333qu6ujqlpaUFs/2Q0p7v6UGDBunzzz+3g6Qkffrpp0pJSSHgXEJ75nzu3LlWQaYlWFr8eke/6ZC/CwP2lmaDrV692nI6ndaKFSusAwcOWOPHj7fi4+Mtt9ttWZZljR071nrqqafs+u3bt1udOnWy5s6dax08eNCaPn06HyG/Cm2d8/PPP285HA7rX/7lX6z//d//tf+cPn26oy4hJLR1zt/Gp6uuXltnffToUatLly5WUVGRdejQIWvDhg1WYmKiNXv27I66hJDQ1jlPnz7d6tKli/W73/3OOnz4sFVVVWXddNNN1k9/+tOOuoSQcPr0aWvv3r3W3r17LUnW/Pnzrb1791p/+tOfLMuyrKeeesoaO3asXd/yEfJJkyZZBw8etCoqKvgI+XfV4sWLreuvv95yOBzWnXfeae3cudM+9qMf/cjKz8/3qX/rrbesH/zgB5bD4bD69Oljbdy4Mcgdh6a2zLlHjx6WpFZ/pk+fHvzGQ0xbv5+/iZDTNm2d9Y4dO6zMzEzL6XRaN954o/Xss89aFy5cCHLXoactc/Z6vdaMGTOsm266yYqKirLS0tKsJ5980jpx4kTwGw8h//Ef/3HR/+e2zDY/P9/60Y9+1Oqc/v37Ww6Hw7rxxhut119/PaA9hlkW9+IAAIB5eE8OAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEb6fw0YvJhqVUf5AAAAAElFTkSuQmCC"},"metadata":{}}]},{"cell_type":"markdown","source":"# Augmentations","metadata":{}},{"cell_type":"code","source":"# def get_train_transforms():\n#     return A.Compose([\n#             A.RandomSizedCrop(min_max_height=(400, 400), height=512, width=512, p=0.5),\n#             A.RandomRotate90(p=0.5),\n#             A.HorizontalFlip(p=0.5),\n#             A.VerticalFlip(p=0.5),\n#             A.Resize(height=512, width=512, p=1),\n#             A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=0.5),\n#             ToTensorV2(p=1.0),                  \n#         ], p=1.0)\n\n# def get_valid_transforms():\n#     return A.Compose([\n#             A.Resize(height=512, width=512, p=1.0),\n#             ToTensorV2(p=1.0),\n#         ], p=1.0)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:19.638375Z","iopub.execute_input":"2024-09-30T06:43:19.638863Z","iopub.status.idle":"2024-09-30T06:43:19.645646Z","shell.execute_reply.started":"2024-09-30T06:43:19.638816Z","shell.execute_reply":"2024-09-30T06:43:19.644892Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"image_size=512\ndef get_train_transforms():\n    return A.Compose([\n           A.Transpose(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightnessContrast(p=0.5),  # Adjust brightness and contrast\n#     A.RandomContrast(limit=0.2, p=0.75),\n    A.OneOf([\n        A.MotionBlur(blur_limit=5),\n        A.MedianBlur(blur_limit=5),\n        A.GaussianBlur(blur_limit=5),\n        A.GaussNoise(var_limit=(5.0, 30.0)),\n    ], p=0.7),\n\n    A.OneOf([\n        A.OpticalDistortion(distort_limit=1.0),\n        A.GridDistortion(num_steps=5, distort_limit=1.),\n        A.ElasticTransform(alpha=3),\n    ], p=0.7),\n\n    A.CLAHE(clip_limit=4.0, p=0.7),\n    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n    A.Resize(image_size, image_size),\n    A.CoarseDropout(max_h_size=int(image_size * 0.375), max_w_size=int(image_size * 0.375), num_holes=1, p=0.7),    \n    A.Normalize(),\n            ToTensorV2(p=1.0),                  \n        ])\n\ndef get_valid_transforms():\n    return A.Compose([\n           A.Resize(image_size, image_size),\n    A.Normalize(),\n    ToTensorV2(p=1.0),                  \n\n        ])","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:19.649098Z","iopub.execute_input":"2024-09-30T06:43:19.649419Z","iopub.status.idle":"2024-09-30T06:43:19.660814Z","shell.execute_reply.started":"2024-09-30T06:43:19.649388Z","shell.execute_reply":"2024-09-30T06:43:19.659994Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"TRAIN_ROOT_PATH = f'{DATA_PATH}/512x512-dataset-melanoma/512x512-dataset-melanoma'\n\ndef onehot(size, target):\n    vec = torch.zeros(size, dtype=torch.float32)\n    vec[target] = 1.\n    return vec\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self,df: pd.DataFrame, image_ids, labels, transforms=None,meta_features=None):\n        super().__init__()\n        self.image_ids = image_ids\n        self.labels = labels\n        self.transforms = transforms\n        self.df = df\n#         self.train = train\n        self.meta_features = meta_features\n        \n\n    def __getitem__(self, idx: int):\n        image_id = self.image_ids[idx]\n        image = cv2.imread(f'{TRAIN_ROOT_PATH}/{image_id}.jpg', cv2.IMREAD_COLOR)\n        \n\n        label = self.labels[idx]\n\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n#             image = image.astype(np.float32) / 255.0\n\n        target = onehot(2, label)\n        \n        \n        meta = np.array(self.df.loc[self.df['image_id'] == image_id][self.meta_features].values, dtype=np.float32)\n#         print(meta.shape)\n        \n        return  (image, meta)  , target\n\n    def __len__(self) -> int:\n        return self.image_ids.shape[0]\n\n    def get_labels(self):\n        return list(self.labels)\n    \nclass MelanomaDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, imfolder: str, isic_imfolder: str = None, train: bool = True, transforms=None, meta_features=None):\n        \"\"\"\n        Class initialization\n        Args:\n            df (pd.DataFrame): DataFrame with data description\n            imfolder (str): folder with images\n            isic_imfolder (str): optional folder with ISIC images\n            train (bool): flag of whether a training dataset is being initialized or testing one\n            transforms: image transformation method to be applied\n            meta_features (list): list of features with meta information, such as sex and age\n        \"\"\"\n        self.df = df\n        self.imfolder = imfolder\n        self.isic_imfolder = isic_imfolder  # New parameter for ISIC images\n        self.transforms = transforms\n        self.train = train\n        self.meta_features = meta_features\n        \n    def get_image_path(self, image_name):\n        \"\"\"\n        Helper function to get the full image path.\n        Checks the main image folder first, then the ISIC folder if specified.\n        \"\"\"\n        # Construct main image path\n        main_path = os.path.join(self.imfolder, f\"{image_name}.jpg\")\n        if os.path.exists(main_path):\n            return main_path\n        \n        # If ISIC images are needed, check in the ISIC folder\n        if False:\n            isic_path = os.path.join(self.isic_imfolder, f\"{image_name}.jpg\")\n            if os.path.exists(isic_path):\n                return isic_path\n        \n        # Raise an error if the image is not found in either location\n        raise FileNotFoundError(f\"Image {image_name} not found in both folders.\")\n\n    def __getitem__(self, index):\n        # Get the image name from the DataFrame\n        image_name = self.df.iloc[index]['image_id']\n        \n        # Use the helper function to get the full image path\n        im_path = self.get_image_path(image_name)\n        \n        # Load the image\n        x = cv2.imread(im_path)\n        x = x.astype(np.float32) / 255.0\n\n        \n        # Extract meta features\n        meta = np.array(self.df.iloc[index][self.meta_features].values, dtype=np.float32)\n        print(meta.shape)\n        # Convert image to RGB\n#         image = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n\n        # Apply transformations if any\n        if self.transforms is not None:\n            res = self.transforms(image=x)\n            x = res['image']\n        else:\n            x = image.astype(np.float32)\n\n        # Change channel order from HWC to CHW\n#         x = x.transpose(2, 0, 1)\n            \n        # Return the tuple of (image, meta) and label if in training mode\n        if self.train:\n            y = self.df.iloc[index]['target']\n            return (x, meta), y\n        else:\n            return (x, meta)\n    \n    def __len__(self):\n        return len(self.df)\n    ","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-09-30T06:43:19.662033Z","iopub.execute_input":"2024-09-30T06:43:19.662416Z","iopub.status.idle":"2024-09-30T06:43:19.681745Z","shell.execute_reply.started":"2024-09-30T06:43:19.662375Z","shell.execute_reply":"2024-09-30T06:43:19.680790Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"# Metrics","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\nclass RocAucMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.y_true = np.array([0,1])\n        self.y_pred = np.array([0.5,0.5])\n        self.score = 0\n\n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().argmax(axis=1).clip(min=0, max=1).astype(int)\n        # y_pred = 1 - nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,0]\n        y_pred = nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,1]\n        self.y_true = np.hstack((self.y_true, y_true))\n        self.y_pred = np.hstack((self.y_pred, y_pred))\n        self.score = sklearn.metrics.roc_auc_score(self.y_true, self.y_pred)\n\n    @property\n    def avg(self):\n        return self.score\n\n    \nclass APScoreMeter(RocAucMeter):\n    def __init__(self):\n        super(APScoreMeter, self).__init__()\n\n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().argmax(axis=1).clip(min=0, max=1).astype(int)\n        y_pred = nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,1]\n        self.y_true = np.hstack((self.y_true, y_true))\n        self.y_pred = np.hstack((self.y_pred, y_pred))\n        self.score = sklearn.metrics.average_precision_score(self.y_true, self.y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:19.682934Z","iopub.execute_input":"2024-09-30T06:43:19.683259Z","iopub.status.idle":"2024-09-30T06:43:19.696685Z","shell.execute_reply.started":"2024-09-30T06:43:19.683227Z","shell.execute_reply":"2024-09-30T06:43:19.695639Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"# Loss","metadata":{}},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.logits = logits\n        self.reduce = reduce\n\n    def forward(self, inputs, targets):\n        if self.logits:\n            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets)\n        else:\n            BCE_loss = F.binary_cross_entropy(inputs, targets)\n\n        pt = torch.exp(-BCE_loss)\n        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n\n        if self.reduce:\n            return torch.mean(F_loss)\n        else:\n            return F_loss\n        \nclass LabelSmoothing(nn.Module):\n    def __init__(self, smoothing = 0.1):\n        super(LabelSmoothing, self).__init__()\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n\n    def forward(self, x, target):\n        if self.training:\n            x = x.float()\n            target = target.float()\n            logprobs = torch.nn.functional.log_softmax(x, dim = -1)\n\n            nll_loss = -logprobs * target\n            nll_loss = nll_loss.sum(-1)\n    \n            smooth_loss = -logprobs.mean(dim=-1)\n\n            loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n\n            return loss.mean()\n        else:\n            return torch.nn.functional.cross_entropy(x, target)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:19.697828Z","iopub.execute_input":"2024-09-30T06:43:19.698202Z","iopub.status.idle":"2024-09-30T06:43:19.709294Z","shell.execute_reply.started":"2024-09-30T06:43:19.698162Z","shell.execute_reply":"2024-09-30T06:43:19.708568Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"# Net","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# from efficientnet_pytorch import EfficientNet\n\n# def get_net():\n#     net = EfficientNet.from_pretrained('efficientnet-b5')\n#     net._fc = nn.Linear(in_features=2048, out_features=2, bias=True)\n#     return net\n\n# net = get_net().cuda()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-09-30T06:43:19.710453Z","iopub.execute_input":"2024-09-30T06:43:19.710802Z","iopub.status.idle":"2024-09-30T06:43:19.721847Z","shell.execute_reply.started":"2024-09-30T06:43:19.710771Z","shell.execute_reply":"2024-09-30T06:43:19.721078Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/melanoma-merged-external-data-512x512-jpeg/folds.csv')\ntest_df = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/test.csv')\n# isic_train_df = pd.read_csv('/kaggle/input/jpeg-isic2019-512x512//train.csv')\n\n# Concatenate the two datasets for training\n# train_df = pd.concat([train_df, isic_train_df], axis=0, ignore_index=True)\n\n# One-hot encoding of anatom_site_general_challenge feature\nconcat = pd.concat([train_df['anatom_site_general_challenge'], test_df['anatom_site_general_challenge']], ignore_index=True)\ndummies = pd.get_dummies(concat, dummy_na=True, dtype=np.uint8, prefix='site')\ntrain_df = pd.concat([train_df, dummies.iloc[:train_df.shape[0]]], axis=1)\ntest_df = pd.concat([test_df, dummies.iloc[train_df.shape[0]:].reset_index(drop=True)], axis=1)\n\n# Sex features\ntrain_df['sex'] = train_df['sex'].map({'male': 1, 'female': 0})\ntest_df['sex'] = test_df['sex'].map({'male': 1, 'female': 0})\ntrain_df['sex'] = train_df['sex'].fillna(-1)\ntest_df['sex'] = test_df['sex'].fillna(-1)\n\n# Age features\ntrain_df['age_approx'] /= train_df['age_approx'].max()\ntest_df['age_approx'] /= test_df['age_approx'].max()\ntrain_df['age_approx'] = train_df['age_approx'].fillna(0)\ntest_df['age_approx'] = test_df['age_approx'].fillna(0)\n\ntrain_df['patient_id'] = train_df['patient_id'].fillna(0)\nmeta_features = ['sex', 'age_approx'] + [col for col in train_df.columns if 'site_' in col]\nmeta_features.remove('anatom_site_general_challenge')","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:19.723030Z","iopub.execute_input":"2024-09-30T06:43:19.723445Z","iopub.status.idle":"2024-09-30T06:43:19.884903Z","shell.execute_reply.started":"2024-09-30T06:43:19.723404Z","shell.execute_reply":"2024-09-30T06:43:19.884083Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, arch, n_meta_features: int):\n        super(Net, self).__init__()\n        self.arch = arch\n        self.dropouts = nn.ModuleList([\n            nn.Dropout(0.5) for _ in range(5)\n        ])\n        if 'ResNet' in str(arch.__class__):\n            self.arch.fc = nn.Linear(in_features=512, out_features=500, bias=True)\n        elif 'EfficientNet' in str(arch.__class__):\n            \n            \n            \n#             net = EfficientNet.from_pretrained('efficientnet-b5')\n#             net._fc = nn.Linear(in_features=2048, out_features=2, bias=True)\n            self.arch._fc = nn.Linear(in_features=2048, out_features=500, bias=True)\n        elif 'Xception' in str(arch.__class__):\n            self.arch.fc = nn.Linear(in_features=2048, out_features=500, bias=True)  # Xception typically has 2048 features\n        \n        self.meta = nn.Sequential(nn.Linear(n_meta_features, 500),\n                                  nn.BatchNorm1d(500),\n                                  nn.ReLU(),\n                                  nn.Dropout(p=0.2),\n                                  nn.Linear(500, 250),  # FC layer output will have 250 features\n                                  nn.BatchNorm1d(250),\n                                  nn.ReLU(),\n                                  nn.Dropout(p=0.2))\n        self.ouput = nn.Linear(500 + 250, 2)\n        \n    def forward(self, inputs):\n        \"\"\"\n        No sigmoid in forward because we are going to use BCEWithLogitsLoss\n        Which applies sigmoid for us when calculating a loss\n        \"\"\"\n        x, meta = inputs\n#         print(meta.shape)\n        \n        \n        cnn_features = self.arch(x)\n#         print(cnn_features.shape)\n        meta_features = self.meta(meta.squeeze())\n#         print(meta_features.shape)\n        features = torch.cat((cnn_features, meta_features), dim=1)\n#         for i, dropout in enumerate(self.dropouts):\n#             if i == 0:\n#                 out = self.ouput(dropout(x))\n#             else:\n#                 out += self.ouput(dropout(x))\n        output = self.ouput(features)\n#         out /= len(self.dropouts)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:19.886295Z","iopub.execute_input":"2024-09-30T06:43:19.886692Z","iopub.status.idle":"2024-09-30T06:43:19.899090Z","shell.execute_reply.started":"2024-09-30T06:43:19.886648Z","shell.execute_reply":"2024-09-30T06:43:19.898103Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"## efficientnet-b5 :0.92","metadata":{}},{"cell_type":"code","source":"\nfrom efficientnet_pytorch import EfficientNet\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\narch = EfficientNet.from_pretrained('efficientnet-b5')\nnet = Net(arch=arch, n_meta_features=len(meta_features))  # Initialize model\nnet = net.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:19.900203Z","iopub.execute_input":"2024-09-30T06:43:19.900478Z","iopub.status.idle":"2024-09-30T06:43:20.419373Z","shell.execute_reply.started":"2024-09-30T06:43:19.900448Z","shell.execute_reply":"2024-09-30T06:43:20.418400Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Loaded pretrained weights for efficientnet-b5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Xception?","metadata":{}},{"cell_type":"code","source":"# !pip install timm\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:20.420555Z","iopub.execute_input":"2024-09-30T06:43:20.420860Z","iopub.status.idle":"2024-09-30T06:43:20.425138Z","shell.execute_reply.started":"2024-09-30T06:43:20.420828Z","shell.execute_reply":"2024-09-30T06:43:20.424154Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"# !pip show torch\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:20.426402Z","iopub.execute_input":"2024-09-30T06:43:20.426760Z","iopub.status.idle":"2024-09-30T06:43:20.435093Z","shell.execute_reply.started":"2024-09-30T06:43:20.426719Z","shell.execute_reply":"2024-09-30T06:43:20.434122Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"# import timm  # Import timm for loading Xception\n\n# arch = timm.create_model('xception', pretrained=True)\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# net = Net(arch=arch, n_meta_features=len(meta_features))  # Initialize model\n# net = net.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:20.436325Z","iopub.execute_input":"2024-09-30T06:43:20.436762Z","iopub.status.idle":"2024-09-30T06:43:20.448322Z","shell.execute_reply.started":"2024-09-30T06:43:20.436720Z","shell.execute_reply":"2024-09-30T06:43:20.447422Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"# Fitter","metadata":{}},{"cell_type":"code","source":"class Fitter:\n    \n    def __init__(self, model, device, config, folder):\n        self.config = config\n        self.epoch = 0\n\n        self.base_dir = f'./{folder}'\n        if not os.path.exists(self.base_dir):\n            os.makedirs(self.base_dir)\n\n        self.log_path = f'{self.base_dir}/log.txt'\n        self.best_score = 0\n        self.best_loss = 10**5\n        self.best_ap = 0\n        \n        self.model = model\n        self.device = device\n\n        param_optimizer = list(self.model.named_parameters())\n        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n        optimizer_grouped_parameters = [\n            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n        ] \n\n        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.lr)\n        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n\n#         self.criterion = FocalLoss(logits=True).to(self.device)\n        self.criterion = LabelSmoothing().to(self.device)\n        self.log(f'Fitter prepared. Device is {self.device}')\n\n    def fit(self, train_loader, validation_loader):\n        for e in range(self.config.n_epochs):\n            if self.config.verbose:\n                lr = self.optimizer.param_groups[0]['lr']\n                timestamp = datetime.utcnow().isoformat()\n                self.log(f'\\n{timestamp}\\nLR: {lr}')\n\n            t = time.time()\n            summary_loss, roc_auc_scores, ap_scores = self.train_one_epoch(train_loader)\n            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n\n            t = time.time()\n            summary_loss, roc_auc_scores, ap_scores = self.validation(validation_loader)\n\n            self.log(f'[RESULT]: Val. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n            if summary_loss.avg < self.best_loss:\n                self.best_loss = summary_loss.avg\n                self.save_model(f'{self.base_dir}/best-loss-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n                for path in sorted(glob(f'{self.base_dir}/best-loss-checkpoint-*epoch.bin'))[:-2]:\n                    os.remove(path)\n                    \n            if roc_auc_scores.avg > self.best_score:\n                self.best_score = roc_auc_scores.avg\n                self.save_model(f'{self.base_dir}/best-score-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n                for path in sorted(glob(f'{self.base_dir}/best-score-checkpoint-*epoch.bin'))[:-2]:\n                    os.remove(path)\n                    \n            if ap_scores.avg > self.best_ap:\n                self.best_ap = ap_scores.avg\n                self.save_model(f'{self.base_dir}/best-ap-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n                for path in sorted(glob(f'{self.base_dir}/best-ap-checkpoint-*epoch.bin'))[:-2]:\n                    os.remove(path)\n\n            if self.config.validation_scheduler:\n                self.scheduler.step(metrics=summary_loss.avg)\n\n            self.epoch += 1\n\n    def validation(self, val_loader):\n        self.model.eval()\n        summary_loss = AverageMeter()\n        roc_auc_scores = RocAucMeter()\n        ap_scores = APScoreMeter()\n        t = time.time()\n        for step, (data, targets) in enumerate(val_loader):\n            images=data[0]\n            if self.config.verbose:\n                if step % self.config.verbose_step == 0:\n                    print(\n                        f'Val Step {step}/{len(val_loader)}, ' + \\\n                        f'summary_loss: {summary_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f} ' + \\\n                        f'time: {(time.time() - t):.5f}', end='\\r'\n                    )\n            with torch.no_grad():\n                targets = targets.to(self.device).float()\n#                 images=\n                batch_size = images.shape[0]\n                data[0] = data[0].to(self.device).float()\n                data[1] = data[1].to(self.device).float()\n\n                \n#                 =images\n                outputs = self.model(data)\n                loss = self.criterion(outputs, targets)\n                roc_auc_scores.update(targets, outputs)\n                ap_scores.update(targets, outputs)\n                summary_loss.update(loss.detach().item(), batch_size)\n\n        return summary_loss, roc_auc_scores, ap_scores\n\n    def train_one_epoch(self, train_loader):\n        self.model.train()\n        summary_loss = AverageMeter()\n        roc_auc_scores = RocAucMeter()\n        ap_scores = APScoreMeter()\n        t = time.time()\n        for step, (data, targets) in enumerate(train_loader):\n            images=data[0]\n\n            if self.config.verbose:\n                if step % self.config.verbose_step == 0:\n                    print(\n                        f'Train Step {step}/{len(train_loader)}, ' + \\\n                        f'summary_loss: {summary_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f} ' + \\\n                        f'time: {(time.time() - t):.5f}', end='\\r'\n                    )\n            \n            targets = targets.to(self.device).float()\n            data[0] = data[0].to(self.device).float()\n            data[1] = data[1].to(self.device).float()            \n            batch_size = images.shape[0]\n            \n            self.optimizer.zero_grad()\n            outputs = self.model(data)\n            loss = self.criterion(outputs, targets)\n            loss.backward()\n            \n            roc_auc_scores.update(targets, outputs)\n            ap_scores.update(targets, outputs)\n            summary_loss.update(loss.detach().item(), batch_size)\n\n            self.optimizer.step()\n\n            if self.config.step_scheduler:\n                self.scheduler.step()\n\n        return summary_loss, roc_auc_scores, ap_scores\n    \n    def save_model(self, path):\n        self.model.eval()\n        torch.save(self.model.state_dict(),path)\n\n    def save(self, path):\n        self.model.eval()\n        torch.save({\n            'model_state_dict': self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            'scheduler_state_dict': self.scheduler.state_dict(),\n            'best_score': self.best_score,\n            'best_ap': self.best_ap,\n            'best_loss': self.best_loss,\n            'epoch': self.epoch,\n        }, path)\n\n    def load(self, path):\n        checkpoint = torch.load(path)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n        self.best_score = checkpoint['best_score']\n        self.best_ap = checkpoint['best_ap']\n        self.best_loss = checkpoint['best_loss']\n        self.epoch = checkpoint['epoch']\n        \n    def log(self, message):\n        if self.config.verbose:\n            print(message)\n        with open(self.log_path, 'a+') as logger:\n            logger.write(f'{message}\\n')","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:20.449676Z","iopub.execute_input":"2024-09-30T06:43:20.450210Z","iopub.status.idle":"2024-09-30T06:43:20.484183Z","shell.execute_reply.started":"2024-09-30T06:43:20.450167Z","shell.execute_reply":"2024-09-30T06:43:20.483281Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"class TrainGlobalConfig:\n    num_workers = 2\n    batch_size = 8 \n    n_epochs = 50\n    lr = 0.00003\n\n    # -------------------\n    verbose = True\n    verbose_step = 1\n    # -------------------\n\n    # --------------------\n    step_scheduler = False  # do scheduler.step after optimizer.step\n    validation_scheduler = True  # do scheduler.step after validation stage loss\n\n#     SchedulerClass = torch.optim.lr_scheduler.OneCycleLR\n#     scheduler_params = dict(\n#         max_lr=0.001,\n#         epochs=n_epochs,\n#         steps_per_epoch=int(len(train_dataset) / batch_size),\n#         pct_start=0.1,\n#         anneal_strategy='cos', \n#         final_div_factor=10**5\n#     )\n    \n    SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n    scheduler_params = dict(\n        mode='min',\n        factor=0.8,\n        patience=1,\n        verbose=False, \n        threshold=0.0001,\n        threshold_mode='abs',\n        cooldown=0, \n        min_lr=1e-8,\n        eps=1e-08\n    )\n    # --------------------","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:20.487221Z","iopub.execute_input":"2024-09-30T06:43:20.487525Z","iopub.status.idle":"2024-09-30T06:43:20.498747Z","shell.execute_reply.started":"2024-09-30T06:43:20.487480Z","shell.execute_reply":"2024-09-30T06:43:20.497865Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"# Save all states for \"honest\" training of folds","metadata":{}},{"cell_type":"code","source":"fitter = Fitter(model=net, device=torch.device('cuda:0'), config=TrainGlobalConfig, folder='base_state')\nBASE_STATE_PATH = f'{fitter.base_dir}/base_state.bin'\nfitter.save(BASE_STATE_PATH)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:20.500018Z","iopub.execute_input":"2024-09-30T06:43:20.500564Z","iopub.status.idle":"2024-09-30T06:43:20.857817Z","shell.execute_reply.started":"2024-09-30T06:43:20.500520Z","shell.execute_reply":"2024-09-30T06:43:20.856781Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"Fitter prepared. Device is cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"from catalyst.data.sampler import BalanceClassSampler\n\ndef train_fold(fold_number):\n    \n    \n    train_dataset = DatasetRetriever(\n        df=train_df,\n        \n        image_ids=df_folds[df_folds['fold'] != fold_number].index.values,\n        labels=df_folds[df_folds['fold'] != fold_number].target.values,\n        transforms=get_train_transforms(),\n        meta_features=meta_features\n\n    )\n\n    df_val = df_folds[(df_folds['fold'] == fold_number) & (df_folds['source'] == 'ISIC20')]\n\n    validation_dataset = DatasetRetriever(\n        df=train_df,\n        image_ids=df_val.index.values,\n        labels=df_val.target.values,\n        transforms=get_valid_transforms(),\n        meta_features=meta_features\n\n    )\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        sampler=BalanceClassSampler(labels=train_dataset.get_labels(), mode=\"downsampling\"),\n        batch_size=TrainGlobalConfig.batch_size,\n        pin_memory=False,\n        drop_last=True,\n        num_workers=TrainGlobalConfig.num_workers,\n    )\n    val_loader = torch.utils.data.DataLoader(\n        validation_dataset, \n        batch_size=TrainGlobalConfig.batch_size,\n        num_workers=TrainGlobalConfig.num_workers,\n        shuffle=False,\n        sampler=SequentialSampler(validation_dataset),\n        pin_memory=False,\n    )\n\n    fitter = Fitter(model=net, device=torch.device('cuda:0'), config=TrainGlobalConfig, folder=f'fold{fold_number}')\n    fitter.load(BASE_STATE_PATH)\n    fitter.fit(train_loader, val_loader)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:20.859580Z","iopub.execute_input":"2024-09-30T06:43:20.859981Z","iopub.status.idle":"2024-09-30T06:43:20.870986Z","shell.execute_reply.started":"2024-09-30T06:43:20.859938Z","shell.execute_reply":"2024-09-30T06:43:20.870195Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n\nfor fold_number in range(1): # range(5)\n    train_fold(fold_number=fold_number)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:43:20.872191Z","iopub.execute_input":"2024-09-30T06:43:20.872525Z","iopub.status.idle":"2024-09-30T11:36:43.783402Z","shell.execute_reply.started":"2024-09-30T06:43:20.872483Z","shell.execute_reply":"2024-09-30T11:36:43.782272Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Fitter prepared. Device is cuda:0\n\n2024-09-30T06:43:21.165467\nLR: 3e-05\n[RESULT]: Train. Epoch: 0, summary_loss: 0.55369, roc_auc: 0.82584, ap: 0.81314, time: 746.72452\n[RESULT]: Val. Epoch: 0, summary_loss: 0.30072, roc_auc: 0.88670, ap: 0.17532, time: 138.26141\n\n2024-09-30T06:58:06.859635\nLR: 3e-05\n[RESULT]: Train. Epoch: 1, summary_loss: 0.51356, roc_auc: 0.86383, ap: 0.85299, time: 740.33481\n[RESULT]: Val. Epoch: 1, summary_loss: 0.27309, roc_auc: 0.90588, ap: 0.21831, time: 136.80815\n\n2024-09-30T07:12:44.903818\nLR: 3e-05\n[RESULT]: Train. Epoch: 2, summary_loss: 0.50124, roc_auc: 0.87426, ap: 0.86935, time: 737.91281\n[RESULT]: Val. Epoch: 2, summary_loss: 0.26275, roc_auc: 0.90481, ap: 0.23524, time: 137.00007\n\n2024-09-30T07:27:20.455557\nLR: 3e-05\n[RESULT]: Train. Epoch: 3, summary_loss: 0.49410, roc_auc: 0.88065, ap: 0.87051, time: 738.62176\n[RESULT]: Val. Epoch: 3, summary_loss: 0.26184, roc_auc: 0.90965, ap: 0.23872, time: 137.02703\n\n2024-09-30T07:41:56.856436\nLR: 3e-05\n[RESULT]: Train. Epoch: 4, summary_loss: 0.47600, roc_auc: 0.89469, ap: 0.88922, time: 740.59865\n[RESULT]: Val. Epoch: 4, summary_loss: 0.26170, roc_auc: 0.91788, ap: 0.25323, time: 137.64508\n\n2024-09-30T07:56:35.876279\nLR: 3e-05\n[RESULT]: Train. Epoch: 5, summary_loss: 0.47020, roc_auc: 0.89899, ap: 0.89514, time: 745.28658\n[RESULT]: Val. Epoch: 5, summary_loss: 0.28624, roc_auc: 0.92823, ap: 0.27080, time: 137.45675\n\n2024-09-30T08:11:19.138025\nLR: 3e-05\n[RESULT]: Train. Epoch: 6, summary_loss: 0.45286, roc_auc: 0.91146, ap: 0.90478, time: 739.61644\n[RESULT]: Val. Epoch: 6, summary_loss: 0.26443, roc_auc: 0.92188, ap: 0.27974, time: 136.92388\n\n2024-09-30T08:25:55.940633\nLR: 2.4e-05\n[RESULT]: Train. Epoch: 7, summary_loss: 0.43781, roc_auc: 0.92133, ap: 0.91292, time: 745.42066\n[RESULT]: Val. Epoch: 7, summary_loss: 0.25492, roc_auc: 0.92844, ap: 0.32892, time: 137.57107\n\n2024-09-30T08:40:39.755405\nLR: 2.4e-05\n[RESULT]: Train. Epoch: 8, summary_loss: 0.43330, roc_auc: 0.92427, ap: 0.91989, time: 741.94913\n[RESULT]: Val. Epoch: 8, summary_loss: 0.24967, roc_auc: 0.93079, ap: 0.32905, time: 136.89367\n\n2024-09-30T08:55:19.361367\nLR: 2.4e-05\n[RESULT]: Train. Epoch: 9, summary_loss: 0.42792, roc_auc: 0.92780, ap: 0.92582, time: 739.40209\n[RESULT]: Val. Epoch: 9, summary_loss: 0.26801, roc_auc: 0.92884, ap: 0.29357, time: 136.87757\n\n2024-09-30T09:09:55.642614\nLR: 2.4e-05\n[RESULT]: Train. Epoch: 10, summary_loss: 0.42508, roc_auc: 0.92922, ap: 0.92368, time: 739.18987\n[RESULT]: Val. Epoch: 10, summary_loss: 0.25337, roc_auc: 0.92486, ap: 0.29104, time: 137.20891\n\n2024-09-30T09:24:32.042731\nLR: 1.9200000000000003e-05\n[RESULT]: Train. Epoch: 11, summary_loss: 0.41223, roc_auc: 0.93714, ap: 0.93365, time: 741.58626\n[RESULT]: Val. Epoch: 11, summary_loss: 0.27976, roc_auc: 0.93860, ap: 0.32767, time: 137.33023\n\n2024-09-30T09:39:11.216787\nLR: 1.9200000000000003e-05\n[RESULT]: Train. Epoch: 12, summary_loss: 0.41327, roc_auc: 0.93643, ap: 0.93292, time: 748.91753\n[RESULT]: Val. Epoch: 12, summary_loss: 0.26986, roc_auc: 0.93231, ap: 0.32818, time: 138.05404\n\n2024-09-30T09:53:58.190249\nLR: 1.5360000000000002e-05\n[RESULT]: Train. Epoch: 13, summary_loss: 0.40801, roc_auc: 0.93924, ap: 0.93182, time: 746.52020\n[RESULT]: Val. Epoch: 13, summary_loss: 0.25869, roc_auc: 0.92938, ap: 0.32799, time: 138.04186\n\n2024-09-30T10:08:42.753559\nLR: 1.5360000000000002e-05\n[RESULT]: Train. Epoch: 14, summary_loss: 0.40315, roc_auc: 0.94211, ap: 0.93988, time: 745.41708\n[RESULT]: Val. Epoch: 14, summary_loss: 0.26149, roc_auc: 0.93495, ap: 0.33685, time: 137.80681\n\n2024-09-30T10:23:26.240057\nLR: 1.2288000000000002e-05\n[RESULT]: Train. Epoch: 15, summary_loss: 0.40029, roc_auc: 0.94369, ap: 0.93959, time: 746.11237\n[RESULT]: Val. Epoch: 15, summary_loss: 0.26162, roc_auc: 0.93812, ap: 0.34068, time: 136.74658\n\n2024-09-30T10:38:09.358400\nLR: 1.2288000000000002e-05\n[RESULT]: Train. Epoch: 16, summary_loss: 0.39006, roc_auc: 0.94919, ap: 0.94254, time: 742.42012\n[RESULT]: Val. Epoch: 16, summary_loss: 0.26045, roc_auc: 0.93037, ap: 0.34163, time: 137.21191\n\n2024-09-30T10:52:49.252631\nLR: 9.830400000000002e-06\n[RESULT]: Train. Epoch: 17, summary_loss: 0.39577, roc_auc: 0.94622, ap: 0.94394, time: 740.25004\n[RESULT]: Val. Epoch: 17, summary_loss: 0.26005, roc_auc: 0.94244, ap: 0.34993, time: 137.13967\n\n2024-09-30T11:07:27.180351\nLR: 9.830400000000002e-06\n[RESULT]: Train. Epoch: 18, summary_loss: 0.38997, roc_auc: 0.94899, ap: 0.94493, time: 740.29795\n[RESULT]: Val. Epoch: 18, summary_loss: 0.25492, roc_auc: 0.93772, ap: 0.34086, time: 137.22553\n\n2024-09-30T11:22:04.705497\nLR: 7.864320000000002e-06\n[RESULT]: Train. Epoch: 19, summary_loss: 0.38218, roc_auc: 0.95260, ap: 0.94712, time: 741.83160\n[RESULT]: Val. Epoch: 19, summary_loss: 0.25614, roc_auc: 0.93262, ap: 0.33288, time: 137.23525\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Thank you for reading my kernel!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}